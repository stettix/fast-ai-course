{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1: classifying cats and dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains my implementation of the code in week 1 of the Fast AI course.\n",
    "\n",
    "This is a from-scratch implementation of the steps needed to classify the given image data, aiming to be a bit cleaner than the one provided with the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the path to the data. This assumes there's a symlink to the data directory in the directory where this notebook is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"data/dogscats\"\n",
    "path = \"data/dogscats/sample/\"\n",
    "model_path = \"data/models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some imports we'll need in subsequent code. Note that the code in this notebook assumes Python 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "\n",
    "# TODO: add more only as and when needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load (and reload) the utility code we use for later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "import utils; reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model setup\n",
    "\n",
    "In the subsequent steps, we implement the classification using Keras code directly, not using the Vgg16 helper code in the course notebook. First up: import the bits we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import random, permutation\n",
    "#from scipy import misc, ndimage\n",
    "#from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# SPECIAL MAGIC THAT IF WE DON'T SET IT MAKES THINGS BLOW UP!!!  :-/\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a function for adding a VGG16 convolutional block to a model. Each convoluational block adds some zero padding (1 pixel each side), and the actual convolutional layer. This uses convolution with a given number of convolution filters, and 3x3 convolution kernel, and 'relu' activation (a rectified linear unit, i.e. with activation function $f(x)=max(0,x)$, a ramp function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_conv_block(model, layers, filters):\n",
    "    for i in range(layers): \n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one adds a fully connected block, with 4096 nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fully_connected_block(model):\n",
    "    model.add(Dense(4096, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the preprocessing of image data to fit the VGG model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of each channel as provided by VGG researchers\n",
    "vgg_mean = np.array([123.68, 116.779, 103.939]).reshape((3,1,1))\n",
    "\n",
    "def vgg_preprocess(x):\n",
    "    x = x - vgg_mean     # subtract mean\n",
    "    return x[:, ::-1]    # reverse axis bgr->rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function defines the network architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16_model():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(vgg_preprocess, input_shape = (3, 224, 224)))\n",
    "    \n",
    "    add_conv_block(model, 2, 64)\n",
    "    add_conv_block(model, 2, 128)\n",
    "    add_conv_block(model, 3, 256)\n",
    "    add_conv_block(model, 3, 512)\n",
    "    add_conv_block(model, 3, 512)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    add_fully_connected_block(model)\n",
    "    add_fully_connected_block(model)\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create us a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg16_model()\n",
    "# model = VGG_16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the weights into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = get_file('vgg16.h5', model_path + 'vgg16.h5', cache_subdir='models')\n",
    "model.load_weights(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll grab some images already classified as dogs or cats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "def get_batches(dirname, gen=image.ImageDataGenerator(), shuffle=True, \n",
    "                batch_size=batch_size, class_mode='categorical'):\n",
    "    return gen.flow_from_directory(path + dirname, target_size=(224,224), \n",
    "                class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_batches = get_batches('train', batch_size=batch_size)\n",
    "validation_batches = get_batches('valid', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at some of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(training_batches)\n",
    "utils.plot_images(imgs, titles=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the model we have so far can predict imagenet classes. We want to customise this model to predict cats or dogs instead.\n",
    "\n",
    "In other words, we want to replicate the \"fine tune\" and\"fit\" steps in the provided Vgg16 class, but we'll do this directly using the Keras API instead. Then, we'll use the resulting model to predict classifications for the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, pop off the last layer of the model (the 1000-node softmax layer), and add a 2-node one instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mark all the remaining layers as non-trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers: layer.trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a new final layer, 2-node softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model needs to be compiled before we can fit it on data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001),\n",
    "                loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, find the class labels we will use (ordered by their label index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get class labels and indexes from the batches we read earlier\n",
    "indexes_to_classes = dict((v,k) for k,v in training_batches.class_indices.items())\n",
    "in_index_order = dict(sorted(indexes_to_classes.items()))\n",
    "classes = list(in_index_order.values())\n",
    "print(\"Class labels: \", classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit the updated model to our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(training_batches, samples_per_epoch=training_batches.nb_sample, nb_epoch=1,\n",
    "                validation_data=validation_batches, nb_val_samples=validation_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

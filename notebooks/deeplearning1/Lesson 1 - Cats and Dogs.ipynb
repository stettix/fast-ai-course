{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1: classifying cats and dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains my implementation of the code in week 1 of the Fast AI course.\n",
    "\n",
    "This is a from-scratch implementation of the steps needed to classify the given image data, aiming to be a bit cleaner than the one provided with the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the path to the data. This assumes there's a symlink to the data directory in the directory where this notebook is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"data/dogscats/\"\n",
    "# path = \"data/dogscats/sample/\"\n",
    "model_path = \"http://files.fast.ai/models/\"\n",
    "validation_path = path + '/valid/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some imports we'll need in subsequent code. Note that the code in this notebook assumes Python 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load (and reload) the utility code we use in later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "import utils; reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model setup\n",
    "\n",
    "In the subsequent steps, we implement the classification using the Keras API, not using the `Vgg16` helper code in the course notebook. First up: import the bits we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.random import random, permutation\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# SPECIAL GLOBAL MAGIC SETTING THAT IF WE DON'T SET IT MAKES THINGS BLOW UP!!!  :-/\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a neural network that implements the VGG16 model, i.e. a well-known model that has been trained for image recognition using a defined architecture and set of published weights. The following sections will build us such a model which we can then use for our cats and dogs data.\n",
    "\n",
    "First up is a function for adding a VGG16 convolutional block to a model. Each convolutional block adds some zero padding (1 pixel each side), and the actual convolutional layer. This uses convolution with a given number of convolution filters, and 3x3 convolution kernel, and 'relu' activation (a rectified linear unit, i.e. with activation function $f(x)=max(0,x)$, a ramp function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_conv_block(model, layers, filters):\n",
    "    for i in range(layers): \n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one adds a fully connected block, with 4096 nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_fully_connected_block(model):\n",
    "    model.add(Dense(4096, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the preprocessing of image data to fit the VGG model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mean of each channel as provided by VGG researchers\n",
    "vgg_mean = np.array([123.68, 116.779, 103.939]).reshape((3,1,1))\n",
    "\n",
    "def vgg_preprocess(x):\n",
    "    x = x - vgg_mean     # subtract mean\n",
    "    return x[:, ::-1]    # reverse axis bgr->rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function defines the network architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg16_model():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(vgg_preprocess, input_shape = (3, 224, 224)))\n",
    "    \n",
    "    add_conv_block(model, 2, 64)\n",
    "    add_conv_block(model, 2, 128)\n",
    "    add_conv_block(model, 3, 256)\n",
    "    add_conv_block(model, 3, 512)\n",
    "    add_conv_block(model, 3, 512)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    add_fully_connected_block(model)\n",
    "    add_fully_connected_block(model)\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create us a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = vgg16_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the weights into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpath = get_file('vgg16.h5', model_path + 'vgg16.h5', cache_subdir='models')\n",
    "model.load_weights(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll grab some images already classified as dogs or cats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def get_batches(dirname, gen=image.ImageDataGenerator(), shuffle=True, \n",
    "                batch_size=batch_size, class_mode='categorical'):\n",
    "    return gen.flow_from_directory(path + dirname, target_size=(224, 224), \n",
    "                class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_batches = get_batches('train', batch_size=batch_size)\n",
    "validation_batches = get_batches('valid', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at some of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_batches = get_batches('train', batch_size=batch_size)\n",
    "imgs, labels = next(sample_batches)\n",
    "utils.plot_images(imgs[:6], titles=labels[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the model we have so far can predict ImageNet classes. We want to customise this model to predict cats or dogs instead.\n",
    "\n",
    "We do this by replicating the \"fine tune\" and\"fit\" steps in the provided Vgg16 class, but we'll do this directly using the Keras API instead. Then, we'll use the resulting model to predict classifications for the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, pop off the last layer of the model (the 1000 node softmax layer), and add a 2 node one instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mark all the remaining layers as non-trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers: layer.trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a new final layer, 2-node softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an possible improvement over the basic case, fine tune the previous layer as well(?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "\n",
    "# Make the last 3 layers trainable, i.e. the final dense layer we added but also the previous dense + dropout layers.\n",
    "for layer in model.layers[-3:]: layer.trainable=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model needs to be compiled before we can fit it on data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001),\n",
    "                loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, find the class labels we will use (ordered by their label index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We get class labels and indexes from the batches we read earlier\n",
    "indexes_to_classes = dict((v,k) for k,v in training_batches.class_indices.items())\n",
    "in_index_order = dict(sorted(indexes_to_classes.items()))\n",
    "# Get the classes in order of their index values\n",
    "classes = list(in_index_order.values())\n",
    "print(\"Class labels: \", classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit the updated model to our training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_history = model.fit_generator(training_batches, samples_per_epoch=training_batches.nb_sample, nb_epoch=1,\n",
    "                       validation_data=validation_batches, nb_val_samples=validation_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some example training stats, for future reference.\n",
    "\n",
    "3 epochs on network, fine tuning last dense layer only:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Epoch 1/3\n",
    "23000/23000 [=========================] - 647s - loss: 0.1163 - acc: 0.9719 - val_loss: 0.0509 - val_acc: 0.9875\n",
    "Epoch 2/3\n",
    "23000/23000 [=========================] - 643s - loss: 0.0924 - acc: 0.9785 - val_loss: 0.0453 - val_acc: 0.9910\n",
    "Epoch 3/3\n",
    "23000/23000 [=========================] - 643s - loss: 0.0940 - acc: 0.9792 - val_loss: 0.0599 - val_acc: 0.9875\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 epoch, fine tuning last 3 layers (last two dense layers and dropout in between):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Epoch 1/1\n",
    "23000/23000 [==========================] - 654s - loss: 0.7241 - acc: 0.9522 - val_loss: 0.6085 - val_acc: 0.9615\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save_weights('fitted_weights_1epoch-finetune3layers.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the whole model as well, so we can very quickly pick up where we left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('cats-dogs-model_1epoch-finetune3layers.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, just create a model and load the weights instead of training the model (run this step instead of the training step above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.load_weights('fitted_weights_1.h5')\n",
    "#model = keras.models.load_model('cats-dogs-model_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the model for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a model that we can use to classify images! Let's try it out!\n",
    "\n",
    "Here are some images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "sample_test_batches = get_batches('test', batch_size=batch_size, class_mode=None)\n",
    "images = next(sample_test_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the first few images so we can check the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "utils.plot_images(images[:8], titles=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(images)\n",
    "print(predictions[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good eh!\n",
    "\n",
    "So, now we need to run this across all the files in a given test set and produce a verdict on the cat-vs-dogness of the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_batches = get_batches('test', batch_size=batch_size, shuffle=False, class_mode=None)\n",
    "all_test_predictions = model.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(all_test_predictions[:8])\n",
    "max_score_idxs = np.argmax(all_test_predictions, axis=1)\n",
    "print(max_score_idxs[:8])\n",
    "print(test_batches.filenames[:8], len(test_batches.filenames))\n",
    "max_score_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "filenames = list(map((lambda fn: pathlib.Path(fn).stem), test_batches.filenames))\n",
    "file_ids = np.array(filenames)[:test_batches.nb_sample]\n",
    "clipped_probs = np.clip(max_score_idxs, 0.05, 0.95)\n",
    "results = np.column_stack([file_ids, clipped_probs])\n",
    "print(results[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write out a CSV file in a suitable format for submission to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_filename = 'catsdogs-redux-7.csv'\n",
    "np.savetxt(submission_filename, results, fmt='%s', delimiter=',', header='id,label', comments = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a handy link to the generated file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(submission_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some of the results to get a feel for whether they are good or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, calculate predictions on validation set, so we can find correct and incorrect examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.load_weights('fitted_weights_1.h5')\n",
    "#val_batches, probs = vgg.test(valid_path, batch_size = batch_size)\n",
    "eval_batches = get_batches('valid', batch_size=batch_size, class_mode=None)\n",
    "eval_preds = model.predict_generator(eval_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join up with the correct answers for these images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = eval_batches.filenames\n",
    "expected_labels = eval_batches.classes #0 or 1\n",
    "\n",
    "#Round our predictions to 0/1 to generate labels\n",
    "our_predictions = eval_preds[:,0]\n",
    "our_labels = np.round(1 - our_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper code for easily plotting results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "#Helper function to plot images by index in the validation set \n",
    "#Plots is a helper function in utils.py\n",
    "def plots_idx(idx, titles=None):\n",
    "    utils.plot_images([image.load_img(validation_path + filenames[i]) for i in idx], titles=titles)\n",
    "    \n",
    "#Number of images to view for each visualization task\n",
    "n_view = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, some random correct results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(our_labels[:4], expected_labels[:4])\n",
    "#TODO! one array has floats and the other has ints - how to convert?\n",
    "correct = np.where(our_labels == expected_labels)[0]\n",
    "print \"Found %d correct labels\" % len(correct)\n",
    "#idx = permutation(correct)[:n_view]\n",
    "#plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
